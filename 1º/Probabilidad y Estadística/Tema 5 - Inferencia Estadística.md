En esta tema buscaremos trabajar con distribuciones donde los par谩metros son desconocidos, por ello el nombre de nuestro tema es [[Inferencia Estad铆stica]].

En la vida real no sabemos cu谩l es la distribuci贸n que depende de unos par谩metros que tampoco se conocen. En este curso solo asumiremos la distribuci贸n, pero escasear谩n los par谩metros, contrario al [[Tema 4 - Variables Aleatorias]] en el cual s铆 conoc铆amos la distribuci贸n y los par谩metros que necesit谩bamos para aplicar una soluci贸n al problema. 

La inferencia se puede obtener de tres formas:

- Estimaci贸n puntual --> Dar un valor puntual para aproximar nuestros par谩metros.
- Estimaci贸n intervalos --> Lo mismo que estimaci贸n puntual pero en intervalos.
- Contrastes Hip贸tesis --> Plantear una hip贸tesis, su alternativa, recogemos datos y lo que hemos de preguntarnos es si utilizando dichos datos, tendr铆a sentido decir si mu es mayor que un dato o menos que el mismo.

#### Breve introducci贸n a la inferencia estad铆stica

Este apartado sirve a modo de aclaraci贸n de algunos conceptos, vamos a tratar los m谩s importantes que ya tocamos en los primeros temas de la asignatura:

- `Poblaci贸n` -> Conjunto de elementos sometidos a estudio
- `Muestra` -> Subconjunto de la poblaci贸n pero que ha de ser representativa de esta.

Bien, entendido esto, vamos a ver qu茅 tipo de problemas trataremos dentro de este tema, los llamados **problemas param茅tricos**, estos consisten en asumir el tipo de distribuci贸n pero no sus par谩metros. Por lo tanto, el objetivo es obtener informaci贸n sobre los valores de estas medidas.

Como ya se coment贸 brevemente antes, dividimos los problemas de este tema en criterios estad铆sticos: 
1. **Estimaci贸n puntual**
2. **Intervalos de confianza**
3. **Contraste de Hip贸tesis**

#### Estimaci贸n Puntual 

**Estad铆stico** -> Es lo que conocemos como una funci贸n matem谩tica de una muestra (como la media, la varianza, la cuasi varianza, etc.). Sin embargo, es en realidad una variable aleatoria con su consecuente distribuci贸n y sus medidas como la esperanza y la varianza. 

Si tenemos entonces una muestra aleatoria de una poblaci贸n X con una funci贸n de masa *f*. Un estimador puntual de cita es una funci贸n de la muestra que usamos como un aproximador de este mismo valor cita. Usaremos en este curso los siguientes par谩metros:

$$
 Media -(\mu \space \space con \space \space \bar{x}) \\: Varianza -(\sigma^2 \space \space con \space \space s^2 ) \\: Desviaci贸n - (\sigma \space \space con \space \space s)
$$

No obstante, si X sigue una distribuci贸n de Bernoulli con par谩metro p lo calculamos de la siguiente manera:

$$
p \space \space con \space \space \hat{p} = \frac{k}{n} \space \\: k \space siendo \space 茅xitos \\: n \space siendo \space pruebas totales
$$

#### Estimaci贸n por Intervalos de Confianza

Al estimar por este m茅todo tenemos que cita es ahora el nivel de confianza 1 - alpha, siendo alpha = 1 - nivel de confianza. En este caso, tendremos un vector de dos n煤meros, el menor posible y el mayor que definen el intervalo donde argumentamos que se encuentra el valor del par谩metro. 

**驴Qu茅 quiere decir exactamente el nivel de confianza?**

Nos referimos a que, con todas las muestras del mundo y metiendo un intervalo en cada una de ellas, decimos con una certeza del 95% que en estos intervalos de nuestras muestras se encuentra el verdadero valor que buscamos, mientras que el 5% restante de las muestras no tendr铆an en el intervalo el valor que queremos hallar. 

**M茅todo de la cantidad pivotal**

Obtenemos una funci贸n denominada como el m茅todo nos dicta. En esta funci贸n sabemos la distribuci贸n y no dependemos del par谩metro. A partir de esta funci贸n conoceremos dos n煤meros c1 y c2 tales que la probabilidad de que c1 sea menor que la funci贸n pero que c1 sea mayor que esta es igual a 1 - alpha, es decir, al nivel de confianza. Si despejamos cita de esta funci贸n tendr铆amos dos intervalos de confianza. Vamos a ilustrarlo matem谩ticamente para que se vea mejor:

$$
P(c_1 < C(X_1, ..., X_n, \theta) < c_2) = 1 - \alpha
$$
$$
\theta_1(X_1, ..., X_n) < \theta < \theta_2(X_1,...,X_n) 
$$
$$
Intervalo \space de \space confianza = [\theta_1(X_1, ..., X_n)\\,\theta_2(X_1,...,X_n)]
$$
Cabe destacar que el nivel de confianza lo denotamos como 1 - alpha y toma valores entre 0 y 1. Entonces, alpha suele tener valores pr贸ximos a cero. As铆 se verifica que en el centro de la distribuci贸n se encuentra nuestro nivel de confianza y en los extremos se encuentra alpha repartido.

![[Pasted image 20240503204558.png]]

Hay varias distribuciones, pero como se nos dan las f贸rmulas en todos los apuntes, poco hemos de tratar sobre ellas en este documento, dejar茅 posteriormente todas las f贸rmulas que nos interesan, ya que con R veremos que la mayor铆a de c谩lculos son muy f谩ciles de hacer.
##### Resumen de IC

He aqu铆 una tabla con un peque帽o resumen de los intervalos de confianza m谩s comunes que estudiamos en esta asignatura. 

![[Pasted image 20240503205020.png]]

**驴Esto es todo?**
Es absolutamente todo lo que concierne a los posibles casos que pueden salir en este tema, pero como es mejor un c贸digo que mil palabras, luego pondr茅 casos pr谩cticos en R en un apartado de este documento dedicado expresamente a estos ejemplos.
#### Contrastes de Hip贸tesis

Siempre tenemos que contrastar dos hip贸tesis: la **hip贸tesis nula** (que siempre incluye un igual) y la **hip贸tesis alternativa** 

$$
Hip贸tesis \space nula = H_0
$$
$$
Hip贸tesis \space alternativa = H_1
$$

Luego dentro de las hip贸tesis alternativas tenemos diferentes tipos:

$$
Hip贸tesis \space  alternativa \space bilateral \rightarrow tipo \neq
$$
$$
Hip贸tesis \space alternativa \space unilateral \rightarrow tipo \space > o <
$$

Veamos entonces algunos ejemplos:

$$ H_0 \\: \mu \leq 12 \hspace{10mm} H_1 \\: \mu > 12$$
$$ H_0 \\: \mu_E = \mu_T \hspace{10mm} H_1 \\: \mu_E \neq \mu_T $$
$$ H_0 \\: p_M \leq p_H \hspace{10mm} H_1 \\: p_M > p_H $$
##### Observaci贸n

- Si se da evidencia contra Ho, se rechaza este hip贸tesis, y se da por v谩lida la hip贸tesis alternativa.
- En caso contrario, no rechazaremos Ho pero no indica que sea cierto.

##### Errores

###### Tipo 1

Rechazar Ho cuando es cierto -> alpha = P(Error Tipo I)

$$
Significaci贸n \space \space \rightarrow \alpha = P(Rechazar H_0 | H_0 cierto) = P(Tipo I)
$$
###### Tipo 2

No rechazar Ho cuando es falsa -> beta = P(Error Tipo II)

$$ 1 - \beta = P(Rechazar H_0|H_0 falso) = 1 -P(Tipo II) $$
###### Estad铆stico del Contraste

Funci贸n de distribuci贸n conocida que da medida de c贸mo se acercan los resultados de la muestra a la hip贸tesis nula.

###### Contrastes

- **Contraste significativo** -> Ha de caer en la regi贸n de rechazo. Aporta evidencia a favor de la hip贸tesis alternativa.
- **Contraste no significativo** -> No cae en la regi贸n de rechazo. No existen razones para rechazar la hip贸tesis nula a favor de la alternativa.

### Apartado R 
	
En este apartado voy a tratar un poco algunos sobre teor铆a de R y ejercicios del tema, ofreciendo el c贸digo que uso para resolver los mismos.
#### Contrastes de hip贸tesis

Veamos un par de ejemplos que nos van a ayudar a entender un poco m谩s sobre el funcionamiento de R a la hora de usarlo en contrastes de hip贸tesis. Tenemos las siguientes tres funciones que ahora veremos en profundidad.

- **t.test** -> media
- **var.test** -> varianza
- **prop.test** -> proporci贸n

##### La funci贸n t.test()

Esta nos sirve para resolver problemas que conciernen a la media de una poblaci贸n comparadas con otra poblaci贸n hipot茅tica o a la media de dos poblaciones comparadas entre s铆. Todas estas pruebas tienen en com煤n que se basan en una distribuci贸n **t de Student**. Vamos a desglosar la sintaxis de esta funci贸n:

```
t.test(x, y = NULL, alternative = c("two.sided", "less", "greater"), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95)
```

- `x` -> Vector de datos correspondientes a una de las muestras o a la 煤nica.
- `y` -> Segunda muestra. Si no existe, no se incluye.
- `alternative` -> Direcci贸n de la hip贸tesis alternativa, tiene los tres posibles valores que se ven en pantalla - bilateral, unilateral izquierda o unilateral derecha.
- `mu` -> Valor hipot茅tico con el que se compara la media o diferencia de medias.
- `paired` -> Especifica si las dos muestras en caso de que aparezcan son apareadas o no. 
- `var.equal` -> Especifica si podemos suponer varianzas iguales si hay dos medias.
- `conf.level` -> Nivel de confianza.

###### Media de una poblaci贸n (Ejemplo 1 Manual R)

Estos ejemplos que se ver谩n a continuaci贸n son sacados del manual de R aportado por la profesora, solamente vamos a comentarlos brevemente:

**Ejemplo 1** Se sospecha que el nivel medio de glucosa en sangre, en ayunas, de las personas diab茅ticas es de 108 mg/100ml. Para contrastar esta suposici贸n se utilizan an谩lisis de sangre realizados a 45 personas diab茅ticas en ayunas. Los datos se encuentran en el fichero_diabeticos.txt_. 驴Es correcto asumir que la media del nivel de glucosa en ayunas es de 108 mg/100ml? (Util铆cese un nivel de significaci贸n del 5%.

Es evidente que la hip贸tesis busca confirmar que la media es 108mg/100ml. Si denotamos como mu al nivel medio de glucosa en sangre, podemos plantearnos el contraste siguiente:
$$ Ho : \mu = 108 \space frente \space a \space H1: \mu \neq 108$$
Teniendo un tama帽o muestral grande (45), no necesitamos la hip贸tesis de normalidad de datos. Se trata de un contraste sobre la media de una distribuci贸n normal, contraste bilateral.

Digamos que tenemos el fichero *diabeticos.txt*. Veamos c贸mo habr铆amos de ejecutar el c贸digo para realizar el c谩lculo:

```
datos.diabeticos<-read.table("diabeticos.txt",header=TRUE,dec=".")
t.test(datos.diabeticos$glucosa,alternative="two.sided",mu=108)
```

Si ejecut谩semos este c贸digo en R, nos otorgar铆a lo siguiente por pantalla:

```
## 
##  One Sample t-test
## 
## data:  datos.diabeticos$glucosa
## t = -1.6771, df = 44, p-value = 0.1006
## alternative hypothesis: true mean is not equal to 108
## 95 percent confidence interval:
##  103.5965 108.4035
## sample estimates:
## mean of x 
##       106
```

Analicemos esto:

- Nos informa del valor estad铆stico de contraste (*t = -1.6771*), de los grados de libertad (*df = 44*) y del p-valor (*p-value = 0.1006*). As铆, podemos llegar a una conclusi贸n. Dado que el p-valor no es inferior a 0.05 (el valor de alpha) no tenemos suficientes evidencias en los datos para rechazar la hip贸tesis nula de que la media es 108. 
- Nos recuerda la hip贸tesis nula que hab铆amos planteado. 
- Proporciona los estad铆sticos muestrales usados, como en este caso, la media muestral.

Por lo tanto, y a modo de conclusi贸n, podemos decir que no hay evidencias de que la concentraci贸n de glucosa en sangre, en el caso de las personas diab茅ticas, no sea 108.

###### Diferencia de medias poblacionales independientes (Ejemplo 2 Manual R)

**Ejemplo 2** Un ingeniero industrial ha sintetizado en el laboratorio una feromona con la que pretende luchar contra una plaga de insectos. La feromona se aplica en trampas donde caen los insectos masivamente. Hasta ahora se trabajaba introduciendo otro producto que se supone que atra铆a al insecto, por lo que el ingeniero desear铆a demostrar que su feromona sintetizada es m谩s efectiva que dicho producto. Para probar si esto ocurre, prepara 100 trampas con el producto tradicional y 100 con su feromona y las distribuye, contabilizando el n煤mero de insectos atrapados en cada una de las 200 trampas. Con esos datos, 驴puede concluir el ingeniero que su feromona es m谩s efectiva que el producto tradicional?

Vamos a ver la terminolog铆a:

$$ \mu_V : media \space capturas \space viejo \space producto \\, \mu_N : media \space nueva \space feromona $$
$$H_0 : \mu_V \geq \mu_N \hspace{10mm} H_1 : \mu_V < \mu_N $$

Tenemos las siguientes perspectivas a ver:
- Las muestras son independientes. Es obvio que el producto antiguo no ha tenido nada que ver con el nuevo.
- Nos ha de preocupar la hip贸tesis de normalidad, si el tama帽o es peque帽o, deber铆a proceder de una distribuci贸n normal, pero no es el caso: ambas muestras son mayores de 30.
- Debemos plantearnos si podemos suponer varianzas iguales o no.

Veamos c贸mo se usa el c贸digo:

```
feromona<-read.table("feromona.txt",header=TRUE)
t.test(x=feromona$Capturas.feromona, y=feromona$Capturas.producto.tradicional,
alternative="greater",mu=0)
```

Bien, ahora, esto es lo que nos da ejecutarlo:

```
## 
##  Welch Two Sample t-test
## 
## data:  feromona$Capturas.feromona and feromona$Capturas.producto.tradicional
## t = 20.437, df = 197.95, p-value < 2.2e-16
## alternative hypothesis: true difference in means is greater than 0
## 95 percent confidence interval:
##  14.2558     Inf
## sample estimates:
## mean of x mean of y 
##     64.94     49.43
```

Si lo analizamos punto por punto tenemos lo siguiente:
- Especifica que se trata de un test t para variables separadas
- Nos da nuevamente el valor de contraste, los grados de libertad y el p-valor. Como el p-valor es menor que alpha podemos concluir que tenemos evidencias en los datos para afirmar con un 95% de confianza que la media de las capturas con la feromona es superior a las capturas con el viejo producto.
- Especifica la hip贸tesis alternativa.
- Garantiza un intervalo de confianza para la diferencia de las media. El cero no es un valor plausible y hemos rechazado por ello la hip贸tesis nula.
- Brinda las dos medias muestrales.

Podemos concluir que con un 95% de confianza la feromona es m谩s efectiva que el viejo producto.

###### Diferencia de medias apareadas (Ejemplo 3 Manual R)

**Ejemplo 3** En un programa de Control de Enfermedades Cr贸nicas, la hipertensi贸n est谩 incluida como la primera patolog铆a a controlar. 15 pacientes hipertensos son sometidos al programa y su tensi贸n asist贸lica es controlada antes y despu茅s de 6 meses de tratamiento. Los datos son los siguientes:

![[Pasted image 20240505211537.png]]

En este caso tenemos como mu de D al promedio de medidas de tensi贸n asist贸lica despu茅s del tratamiento y por mu de A al mismo promedio antes del tratamiento.

$$ H_0 : \mu_D \geq \mu_A \space frente \space a \space H_1 : \mu_D < \mu_A$$

Veamos el c贸digo:

```
tension<-read.table("tension.txt",header=TRUE,dec=".")
t.test(x=tension$inicio, y=tension$fin, alternative="greater",mu=0,paired=TRUE)
```

Este c贸digo nos brinda la siguiente informaci贸n:

```
## 
##  Paired t-test
## 
## data:  tension$inicio and tension$fin
## t = 4.8316, df = 14, p-value = 0.0001332
## alternative hypothesis: true mean difference is greater than 0
## 95 percent confidence interval:
##  16.09828      Inf
## sample estimates:
## mean difference 
##        25.33333
```

- En las dos primeras l铆neas se nos informa de un test para muestras apareadas.
- Aparece el valor estad铆stico de contraste, grados de libertad y el p-valor. Podemos concluir que existen evidencias en los datos de la muestra que el tratamiento disminuye el promedio de la tensi贸n asist贸lica. El p-valor es muy bajo y por ello las diferencias detectadas son muy significativas.
- Aparece la hip贸tesis alternativa.
- Intervalo de confianza para la diferencia de medias que excluyendo al cero significa que podemos rechazar la nula en favor de la alternativa.
- Aparece el valor muestral de la diferencia de las medias.


##### La funci贸n prop.test()

R nos brinda este tipo de contraste de dos formas, mediante una prueba seg煤n la **distribuci贸n de Pearson** o mediante una prueba binomial exacta. 

En el primer caso se compara la frecuencia de casos favorables en la muestra de los datos con la muestra de casos favorables que habr铆a en una muestra con el mismo n煤mero de datos si la hip贸tesis nula fuera cierta. Se usa estad铆stico:
$$
X^2 = \sum_i \frac{(O_i-E_i)^2}{E_i}
$$
Esto bajo el supuesto de que ninguna frecuencia esperada E es inferior a 5. En el caso de que lo fuera se usa la correci贸n por continuidad de Yates:
$$
X^2 = \sum_i \frac{(|O_i-E_i|-0.5)^2}{E_i}
$$
La prueba binomial parte del hecho que si la hip贸tesis nula fuese cierta, la distribuci贸n del n煤mero de casos favorables en la muestra ser铆a binomial. Valorando el n煤mero observado de casos favorables dentro de la distribuci贸n binomial se obtiene el p-valor. 

Vamos a partir de que conocemos el n煤mero de 茅xitos y fracasos en la muestra. Si no es as铆 y solo tenemos los datos en una hoja de datos, podemos tabularla mediante la funci贸n a la que s贸lo hay que especificarle a la hoja de datos a tabular y si 茅sta tuviera m谩s de una variable, cu谩l queremos tabular. 

Veamos la sintaxis de la funci贸n:

```
prop.test(x, n, p = NULL, alternative = c("two.sided", "less", "greater"),
conf.level = 0.95, correct = TRUE)
```

Mejor comentamos los argumentos de la funci贸n:
- Podemos especificar dos cosas, o bien el n煤mero de 茅xitos o bien mediante una matriz de dos columnas, el n煤mero de 茅xitos y de fracasos en cada muestra.
- Especifica el n煤mero de datos de la muestra en caso de que x sea el n煤mero de 茅xitos, es ignorado en el caso que proporcione tambi茅n el n煤mero de fracasos. 
- Vector de probabilidades de 茅xito bajo la hip贸tesis nula. Debe ser un vector de la misma dimensi贸n que el n煤mero de elementos especificados.
- Especifica la direcci贸n de la hip贸tesis alternativa.
- Nivel de confianza.
- Correci贸n por continuidad de Yates. Por defecto est谩 activada.

###### Proporci贸n en poblaci贸n (Ejemplo 4 Manual R)

**Ejemplo 4** En un determinado servicio de odontolog铆a se espera que aproximadamente el 75%de las visitas no requieran una extracci贸n dentaria inmediata. En cierto a帽o, de 1225 visitas, 926 no necesitaron una extracci贸n inmediata. 驴Se puede decir que el porcentaje de ese a帽o fue significativamente superior al porcentaje esperado?

Si denotamos por *p* la proporci贸n de visitas que no requieren extracci贸n, se nos pide que contrastemos lo siguiente:
$$H_0:p=0.75\hspace{10mm}H_1:p>0.75$$
Podemos resolver el contraste usando:

```
prop.test(x=926,n=1225,p=0.75,alternative="greater",correct=FALSE)
```

```
## 
##  1-sample proportions test without continuity correction
## 
## data:  926 out of 1225, null probability 0.75
## X-squared = 0.22884, df = 1, p-value = 0.3162
## alternative hypothesis: true p is greater than 0.75
## 95 percent confidence interval:
##  0.7351821 1.0000000
## sample estimates:
##         p 
## 0.7559184
```

Analizamos lo siguiente:

- Especificamos que se trata de un test para la proporci贸n en una muestra.
- Especifica a continuaci贸n el valor hipot茅tico en la hip贸tesis nula.
- Brinda el valor del estad铆stico y lo que m谩s nos interesa, el *p-valor*. En este caso el p-valor es bastante superior es 0.05, luego sabiendo que no podemos rechazar la hip贸tesis nula en favor de la alternativa, es decir, no podemos concluir que el porcentaje de visitas est茅 por encima del 75%
- Recuerda la hip贸tesis alternativa
- Facilita un intervalo de confianza para la proporci贸n.
- Proporci贸n muestral.

###### Diferencia de las proporciones (Ejemplo 5 Manual R)

Este tipo de contrastes usan tambi茅n la funci贸n pero hemos de indicar c贸mo usar los datos. Los 茅xitos y los fracasos de cada muestra deben ir en dos filas de una matriz de dos columnas, tal que as铆:

```
##      [,1]  [,2] 
## [1,] "n11" "n12"
## [2,] "n21" "n22"
```

Para crearla usamos la funci贸n *matrix* de esta forma:

```
matrix(c(n11, n12, n21, n22),2,2,byrow=TRUE)
```

Aqu铆 lo que hemos hecho es especificarle mediante un vector los elementos, las dimensiones, y el sentido en el que vienen los elementos. Tambi茅n podr铆amos crearla as铆:

```
matrix(c(n11, n21, n12, n22),2,2,byrow=FALSE).
```

**Ejemplo 5** A ra铆z de la alarma creada entre la opini贸n p煤blica por la repercusi贸n que tuvo el caso de un bloque de edificios con un transformador en su planta baja y donde un gran porcentaje de vecinos sufri贸 c谩ncer, se decide realizar un estudio para tratar de encontrar relaci贸n entre la cercan铆a de un transformador el茅ctrico y la incidencia del c谩ncer.

Para ello, se eligi贸 una muestra aleatoria de edificios con transformadores en su planta baja durante un periodo de m谩s de 10 a帽os, contabilizando el n煤mero de habitantes en ellos, 2150, y todos los casos de c谩ncer detectados en los 5 煤ltimos a帽os, 37. Por su parte, se recolect贸 otra muestra aleatoria de control con edificios que no tuvieran ning煤n transformador el茅ctrico cercano, contabilizando tambi茅n el n煤mero de personas, 2200, y el n煤mero de casos de c谩ncer en ellos en los 煤ltimos 5 a帽os, 33. En ambas muestras, los expertos procuraron eliminar la posibilidad de ruidos, es decir, la presencia de otros factores que pudieran incidir en variar la incidencia del c谩ncer en alguna de las muestras.

A la luz de los datos de este estudio, 驴podemos afirmar que la cercan铆a de un transformador el茅ctrico aumenta la proporci贸n de casos de c谩ncer? (Util铆cese un nivel de significaci贸n del 5%

Si llamamos pct a la proporci贸n de casos de c谩ncer en los edificios con transformador cercano y pst a la proporci贸n an谩loga en los edificios sin transformador, nos piden que contrastemos:

$$H_0 : p_{CT} = p_{ST} \hspace{10mm} H_1 : p_{CT} > p_{ST}$$

Usar铆amos los siguientes comandos:

```
tabla<-matrix(c(37,2113,33,2167),2,2,byrow=TRUE)
```

Finalmente aplicamos la funci贸n:

```
prop.test(tabla, alternative='greater', correct=FALSE)
```

```
## 
##  2-sample test for equality of proportions without continuity correction
## 
## data:  tabla
## X-squared = 0.33521, df = 1, p-value = 0.2813
## alternative hypothesis: greater
## 95 percent confidence interval:
##  -0.004071904  1.000000000
## sample estimates:
##    prop 1    prop 2 
## 0.0172093 0.0150000
```

Lo que nos interesa es el p-valor. Aparece en la tercera l铆nea y indica que no se puede rechazar la hip贸tesis nula en favor de la alternativa. 

##### La funci贸n var.test() (Ejemplo 6 Manual R)

**Ejemplo 6** Un grupo de personas participa en un estudio nutricional que trata de analizar los niveles asimilados de vitamina C en sangre de fumadores y no fumadores. Los resultados enmg/l/se encuentran en el fichero_vitaminac.txt_. Si asumimos que los datos son normales, 驴se puede concluir que el nivel de vitamina C asimilado es superior en los no fumadores?

Con el fin de responder a la pregunta, planteamos las siguientes hip贸tesis:
$$H_0 : \mu_F \geq \mu_{NF} \hspace{10mm} H_1 : \mu_F < \mu_{NF} $$

Observamos que el enunciado no menciona nada relativo a la igualdad de varianzas en ambos grupos, por lo que vamos a plantear en primer lugar un contraste de igualdad de varianzas. Si denotamos sigmaF a la desviaci贸n t铆pica del nivel de vitamina C asimilado en fumadores y sigmaNF a la desviaci贸n t铆pica del nivel de vitamina C asimilado en no fumadores, se trata de contrastar:

$$H_0 : \sigma_F = \sigma_{NF} \hspace{10mm} H_1 : \sigma_F \neq \sigma_{NF} $$
De nuevo vamos a asumir que los datos proceden de distribuciones formales. La funci贸n *var.test()* tiene una sintaxis parecida a las previas funciones:

```
var.test(x, y, ratio = 1, alternative = c("two.sided", "less", "greater"),
conf.level = 0.95)
```

- *x* corresponde al vector de datos de la primera muestra.
- *y* vector de datos de la segunda muestra. 
- *ratio* es el cociente hipot茅tico con el que comparamos. Habitualmente deseamos contrastar que las varianzas son distintas, o lo que no es lo mismo, que su cociente es 1, la opci贸n por defecto es precisamente *ratio = 1*.
- *alternative* especifica la hip贸tesis alternativa "two.sided" para H1 sigmaF != sigma NF, para sigmaF < sigmaNF y para sigmaF > sigmaNF.
- *conf.level* es el nivel de confianza del intervalo para el cociente de varianzas.

```
datos.vitaminac<-read.table("vitaminac.txt",header=TRUE,sep=" ",dec=".") 
datos.vitaminac

##    nivel      tabaco
## 1   18.3   fumadores
## 2    9.3   fumadores
## 3   12.6   fumadores
## 4   15.7   fumadores
## 5   14.2   fumadores
## 6   13.1   fumadores
## 7   14.3   fumadores
## 8   16.2   fumadores
## 9   18.1   fumadores
## 10  19.4   fumadores
## 11  15.5   fumadores
## 12  11.7   fumadores
## 13  24.9 nofumadores
## 14  16.0 nofumadores
## 15  26.3 nofumadores
## 16  25.5 nofumadores
## 17  19.3 nofumadores
## 18  16.8 nofumadores
## 19  15.7 nofumadores
## 20  24.6 nofumadores
## 21  19.9 nofumadores
## 22   9.4 nofumadores
## 23  17.4 nofumadores
```

Veamos el uso de var.test():

```
var.test(datos.vitaminac$nivel[datos.vitaminac$tabaco=="fumadores"], 
datos.vitaminac$nivel[datos.vitaminac$tabaco=="nofumadores"], alternative="two.sided") 

## 
##  F test to compare two variances
## 
## data:  datos.vitaminac$nivel[datos.vitaminac$tabaco == "fumadores"] and datos.vitaminac$nivel[datos.vitaminac$tabaco == "nofumadores"]
## F = 0.31313, num df = 11, denom df = 10, p-value = 0.06976
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.08544081 1.10400497
## sample estimates:
## ratio of variances 
##          0.3131332
```

Alternativamente podr铆amos haber utilizado la funci贸n de *var.test()* de la forma:

```
var.test(nivel ~ tabaco, alternative='two.sided', conf.level=.95,
data=datos.vitaminac)

## 
##  F test to compare two variances
## 
## data:  nivel by tabaco
## F = 0.31313, num df = 11, denom df = 10, p-value = 0.06976
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.08544081 1.10400497
## sample estimates:
## ratio of variances 
##          0.3131332
```

Podemos ver en la tercera l铆nea el valor estad铆stico, los grados de libertad en el numerador y el denominador, sin olvidarnos del p-valor. Este indica que no hay suficientes evidencias en los datos para rechazar la igualdad de varianzas. Por tanto, a la vista de los resultados, realizar铆amos el contraste de medias planteado asumiendo igualdad de varianzas.

