#### Apartado Reconocimiento Facial

El reconocimiento facial es un método de identificación biométrica. Se conoce como una tecnología capaz de identificar a un sujeto a través de una imagen, video, o cualquier elemento audiovisual de su rostro. 

Un estudio de MIT demostró que estos sistemas incurren en sesgo y se producen discriminaciones algorítmicas de género y raza. El estudio puso a prueba tres softwares: Microsoft, IBM y Face++ de Megvii (China). En el caso de hombres blancos margen de error de 1%, en el caso de las mujeres blancas aumentaba a 7% y cuando se trataba de hombres de piel oscura aumentaba al 12% y si eran mujeres de color fallaba en un 35%. 

La problemática radica en la mala calidad de datos.

- ¿Puede un software contener prejuicios de raza y género? Tal y como se comenta en el texto, se puede otorgar un sesgo a un programa que conciba ciertas predisposiciones del algoritmo a cierto colectivo. En el caso de Estados Unidos, cuando se entrena a un algoritmo con datos provenientes de un sistema que posee un odio intrínseco a la raza negra y que cree en la supremacía blanca, pues este modelo interpretará el mundo con los mismos prejuicios.
- ¿Se utiliza inteligencia artificial en la técnica del reconocimiento facial? Los algoritmos de IA se aprovechan mucho dentro de este ámbito, debido a su capacidad de clasificar patrones en cierto grupo y hacer inferencia a partir de los datos visualizados, siendo así un fenómeno de interés para controlar masas y poder registrar de forma correcta a la población. 
- Explica por qué a través de esta tecnología se puede discriminar y vulnerar derechos de las personas
	- Volvemos nuevamente a lo citado en la primera pregunta. Un algoritmo puede atentar contra los derechos de aquellos individuos desfavorecidos ante la sociedad debido al entrenamiento basado en datos a los cuales se someten a estos modelos, otorgándoles así la posibilidad de cometer un daño contra la integridad de las personas.

En España, setenta académicos, profesionales y activistas de distintos ámbitos, reclaman paralizar herramientas de reconocimiento facial hasta que se regulen. Algunas empresas que ya usan esta tecnología son Mercadona y RENFE.

- ¿Qué peligros se encuentran tras el reconocimiento facial y por qué se oponen estos académicos? Bien sabidos son los peligros de un sistema de reconocimiento facial. Muchos conocemos el caso del procesamiento de información biométrica en países como China, donde se utiliza de forma hiperbolizada para clasificar y condicionar a la población en su día a día. Esto también podría ocurrir en España, un sistema que prolifere la desconfianza de los habitantes que se encuentran separados de la verdad por la escasez de transparencia que suele conllevar la implementación de estos algoritmos, y por ello gran cantidad de académicos, en pos de evitar volvernos uno de los países menos libres, votan en contra de su implantación en España. 

#### Apartado COMPAS

COMPAS es un sistema utilizado en muchos juzgados de Estados Unidos que calcula la probabilidad de reincidencia en la comisión de delitos. El sistema se basa en una encuesta a los arrestados. Si bien la encuesta no pregunta la raza, parece ser que la obtiene a partir de otros parámetros, arrojando alto riesgo a ciertas minorías étnicas. Una investigación del Dartmouth College sostenía que el algoritmo falla tanto como una persona al azar que no conoce el ámbito criminalístico. La encuesta pregunta aspectos como si el barrio en el que vive es peligroso, si tiene amigos en una pandilla, su historial laboral y académico, etc. Cada respuesta recibe una puntuación del 1 al 10 y se establece un promedio. El Sr. Loomis participó en un tiroteo en la ciudad de Chicago. COMPAS lo calificó como un individuo de alto riesgo y en 2017 fue sentenciado a seis años de prisión. La empresa no permitió el acceso al algoritmo y la defensa de Loomis recurrió a considerar que se había vulnerado el derecho a un proceso con plenas garantías porque el algoritmo era secreto.

- ¿Pueden existir algoritmos secretos? Lo que conocemos como algoritmo secreto es un sistema de escasa transparencia, los cuales pueden ser nocivos, sobre todo en el ámbito jurídico, debido a la falta de conocimiento sobre su funcionamiento, los datos sobre los que han sido entrenados y su patrón de funcionamiento.
- ¿Cree que se debe hacer público el código fuente? Poner en disponibilidad el código fuente de un algoritmo es vital para la apropiada comprensión de todo el sistema. Esto se vuelve mucho más relevante cuando las decisiones que hace el sistema tienen un peso considerable en la sociedad. Si no permitimos a la población conocer como se forman los algoritmos que moldean nuestra sociedad y buscar ayudarnos en todo, no podemos tratar de asegurarnos la plena confianza de una población que no tendría acceso a toda la verdad.
- ¿Cree que COMPAS puede dar a las minorías étnicas una puntuación de riesgo desproporcionada? Por supuesto. Como sabemos, es posible introducir un sesgo al sistema a través de los datos usados en su entrenamiento. Esto podría permitir que COMPAS excluya socialmente y discrimine a las diferentes minorías que conforman nuestra sociedad. Cabe destacar que el problema no reside en el algoritmo, sino en los datos usados en su formación, que suelen ser introducidos por un ingeniero que habría de filtrarlos y revisarlos antes de llevar a cabo pruebas. 