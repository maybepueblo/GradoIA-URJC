{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7969b53-2265-42dd-a0ec-dac33dca950f",
   "metadata": {},
   "source": [
    "# Funciones de Pérdida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ca3630-b97c-4cb7-9626-3326b1d794cd",
   "metadata": {},
   "source": [
    "### Funciones de Pérdida de Regresión\n",
    "\n",
    "Vamos a comparar cómo diferentes funciones de pérdida afectan al rendimiento de un modelo `SGDRegressor` entrenado en el conjunto de datos anterior.\n",
    "\n",
    "Las funciones de pérdida que vamos a analizar son:\n",
    "\n",
    "\n",
    "1. **L2**:\n",
    "    - La pérdida cuadrática penaliza los errores grandes mucho más que los pequeños debido al término cuadrático.\n",
    "    - Fórmula: \n",
    "    $$\n",
    "    \\mathcal{L}(y, \\hat{y}) = || y^{(i)} - \\hat{y}^{(i)} ||_2^2 =  \\sum_{i=1}^{m} (y^{(i)} - \\hat{y}^{(i)})^2\n",
    "    $$\n",
    "\n",
    "2. **L1**:\n",
    "    - Comparada con la L2,  penaliza menos los errores grandes (linealmente) y penaliza más los errores pequeños.\n",
    "    - Fórmula: \n",
    "    $$\n",
    "    \\mathcal{L}(y, \\hat{y}) = || y^{(i)} - \\hat{y}^{(i)} ||_1 =  \\sum_{i=1}^{m} |y^{(i)} - \\hat{y}^{(i)}|\n",
    "    $$\n",
    "\n",
    "   \n",
    "3. **Huber**:\n",
    "    - Combina la L2 y L1, utilizando L2 para errores pequeños y L1 para errores grandes.\n",
    "    - Fórmula:\n",
    "    $$\n",
    "    \\mathcal{L}(y, \\hat{y}) =\n",
    "    \\begin{cases} \n",
    "    \\frac{1}{2}(y - \\hat{y})^2 & \\text{si } |y - \\hat{y}| \\leq \\delta \\\\\n",
    "    \\delta |y - \\hat{y}| - \\frac{1}{2}\\delta^2 & \\text{si } |y - \\hat{y}| > \\delta\n",
    "    \\end{cases}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1c4fb-f17e-4d18-8135-dcc7e698805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida L2\n",
    "def l2loss(y_true, y_pred):\n",
    "    \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida L1\n",
    "def l1loss(y_true, y_pred):\n",
    "    \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Uber\n",
    "def huber_loss(y_true, y_pred, delta=1.0):\n",
    "    \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Da valores de ejemplo para y_true y y_pred\n",
    "y_true = \n",
    "y_pred = \n",
    "#################################### COMPLETAR ####################################\n",
    "# Calcula las pérdidas para cada función\n",
    "l2loss_v = l2loss(y_true, y_pred)\n",
    "l1loss_v = \n",
    "huber_loss_v = \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Visualiza los resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_true - y_pred, l2loss_v, label='L2')\n",
    "plt.scatter(y_true - y_pred, l1loss_v, label='L1')\n",
    "plt.scatter(y_true - y_pred, huber_loss_v, label='Huber')\n",
    "\n",
    "plt.xlabel(\" $y - \\hat{y}$\")\n",
    "plt.ylabel(\"Pérdida $\\mathcal{L}(y, \\hat{y})$\")\n",
    "plt.title(\"Comparación de Funciones de Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd122526-840d-4558-b05d-0a2bea2feccb",
   "metadata": {},
   "source": [
    "### Funciones de Pérdida de Clasificación\n",
    "\n",
    "\n",
    "1. **Pérdida Logística**:\n",
    "   - Utilizada en problemas de clasificación probabilística. Penaliza más las predicciones erróneas confiadas.\n",
    "   - Fórmula: \n",
    "   $$\n",
    "   \\mathcal{L}(y, \\hat{y}) = -y \\log(\\hat{y}) + -(1 - y) \\log(1 - \\hat{y}) \n",
    "   $$\n",
    "\n",
    "2. **Hinge**:\n",
    "   - Utilizada en SVM, penaliza predicciones incorrectas dentro del margen.\n",
    "   - Fórmula: \n",
    "   $$\n",
    "   \\mathcal{L}(y, \\hat{y})=  \\max(0, 1 - y \\cdot \\hat{y})\n",
    "   $$\n",
    "\n",
    "3. **Perceptron Loss**:\n",
    "   - Penaliza predicciones incorrectas sin margen.\n",
    "   - Fórmula:\n",
    "   $$\n",
    "   \\mathcal{L}(y, \\hat{y})=  \\max(0, -y \\cdot \\hat{y})\n",
    "   $$\n",
    "\n",
    "4. **Binomial**:\n",
    "   - Similar a la logística. Penaliza las predicciones basadas en la desviación binomial entre las probabilidades reales y predichas.\n",
    "   - Fórmula:\n",
    "   $$\n",
    "   \\mathcal{L}(y, \\hat{y}) = \\log\\left(1 + \\exp(-y \\cdot \\hat{y})\\right)\n",
    "   $$\n",
    "\n",
    "6. **Pérdida Exponencial**:\n",
    "   - Penaliza fuertemente los errores grandes.\n",
    "   - Fórmula:\n",
    "   $$\n",
    "   \\mathcal{L}(y, \\hat{y}) =\\exp(-y \\cdot \\hat{y})\n",
    "   $$\n",
    "   \n",
    "   \n",
    "Se pide implementar las diferentes funciones de pérdida definidas en este apartado. **Importante:** Generar las etiquetas y predicciones en el rango que espera cada función de pérdida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412180c5-2a79-4f4a-bb54-922eec3b194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Logística\n",
    "def logloss(y_true, y_pred):\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Hinge\n",
    "def hingeloss(y_true, y_pred):\n",
    "\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Perceptrón\n",
    "def perceptronloss(y_true, y_pred):\n",
    "\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Binomial\n",
    "def binomialloss(y_true, y_pred):\n",
    "\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Define la pérdida Exponencial\n",
    "def exploss(y_true, y_pred):\n",
    "\n",
    "    \n",
    "#################################### COMPLETAR ####################################\n",
    "# Da valores de ejemplo para y_true y y_pred\n",
    "y_true = \n",
    "y_pred = \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Calcula las pérdidas para cada función\n",
    "logloss_v = \n",
    "hingeloss_v = \n",
    "perceptronloss_v = \n",
    "binomialloss_v = \n",
    "exploss_v = \n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Visualiza los resultados\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_true*y_pred, logloss_v, label='Logística')\n",
    "plt.scatter(y_true*y_pred, hingeloss_v, label='Hinge')\n",
    "plt.scatter(y_true*y_pred, perceptronloss_v, label='Perceptron')\n",
    "plt.scatter(y_true*y_pred, binomialloss_v, label='Binomial')\n",
    "plt.scatter(y_true*y_pred, exploss_v, label='Exponencial')\n",
    "\n",
    "# Configuración del gráfico\n",
    "plt.xlabel(\"$y \\cdot\\hat{y}$\")\n",
    "plt.ylabel(\"Pérdida $\\mathcal{L}(y, \\hat{y})$\")\n",
    "plt.title(\"Comparación de Funciones de Pérdida\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.ylim([-0.1,5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3009c292-60a9-4f20-9118-e5252362544d",
   "metadata": {},
   "source": [
    "### Comparación de Funciones de Pérdida en `SGDRegressor`\n",
    "\n",
    "Vamos a comparar cómo diferentes funciones de pérdida afectan al rendimiento de un modelo `SGDRegressor` entrenado en el conjunto de datos anterior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325891a1-8055-4075-a4d6-24d21c7fa1f6",
   "metadata": {},
   "source": [
    "Comenzamos generando datos. Crea unos datos ruidosos a partir de la siguiente función:\n",
    "$$\n",
    "y = 2x + 1 + \\eta, \\quad \\eta \\sim \\mathcal{N}(0,1),\n",
    "$$\n",
    "y, además, añade algunos *outliers* al conjunto de puntos generado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a618a9d-44ff-4c01-9e6c-121494e55095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Generar datos\n",
    "\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Introducir algunos outliers\n",
    "n_outliers = 10\n",
    "\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Visualizar\n",
    "plt.scatter(X, y, color='gray', label='Datos')\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Datos Simulados con Outliers\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a117b0-3a24-4100-97fe-8d3c56f55882",
   "metadata": {},
   "source": [
    "Ahora, importa `SGRegressor` y ajusta los datos anteriores utilizando distintas funciones de pérdida predeterminadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9915506-59fe-4526-a78f-7131fda5032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################### COMPLETAR ####################################\n",
    "# Importa SGDRegressor\n",
    "\n",
    "#################################### COMPLETAR ####################################\n",
    "# Entrena varios modelos con los datos anteriores usando distintas funciones\n",
    "\n",
    "# Lista de funciones de pérdida para probar\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da63bb7f-ab93-4814-9606-aa015de1ed60",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 10px; border-radius: 5px; font-style: italic;\">\n",
    "  ¿Qué puedes concluir de los modelos resultantes?\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
